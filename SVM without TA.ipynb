{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, re, sklearn, string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from datetime import datetime\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    return pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    stopwords = {}\n",
    "    stopwords = set(stop_words.ENGLISH_STOP_WORDS)\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub(r\"[0-9]+\", \"\", doc)\n",
    "    tokens = doc.split()\n",
    "    tokens = [w for w in tokens if not w in stopwords]\n",
    "    tokens = [w.translate(str.maketrans('', '', string.punctuation)) for w in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(word) for word in tokens]    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_voc(reviews):\n",
    "    vocabularyDict = {}\n",
    "    vocabularyList = []\n",
    "    for i in range(len(reviews)):\n",
    "        r = reviews[i]\n",
    "        tokens = set(r.split())\n",
    "        for token in tokens:\n",
    "            if token not in vocabularyDict.keys():\n",
    "                vocabularyDict[token] = 1\n",
    "            else:\n",
    "                vocabularyDict[token] = vocabularyDict[token] + 1    \n",
    "    for key in vocabularyDict.keys():\n",
    "        if vocabularyDict[key] >= 30:\n",
    "            vocabularyList.append(key)\n",
    "    return vocabularyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFeatureVectors(reviews, vocabularyList):\n",
    "    featureXVectors = []\n",
    "    for i in range(len(reviews)):\n",
    "        r = reviews[i]\n",
    "        tokens = set(r.split())\n",
    "        fVector=[]\n",
    "        for token in vocabularyList:\n",
    "            if token in tokens:\n",
    "                fVector.append(1)\n",
    "            else:\n",
    "                fVector.append(0)\n",
    "        featureXVectors.append(fVector)\n",
    "\n",
    "    featureVectors = np.asarray(featureXVectors)\n",
    "    return featureVectors;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_cleaning(data):\n",
    "    review = []\n",
    "    for row in data:\n",
    "        review.append(clean_doc(row))\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data, reviews):\n",
    "    dataX = []\n",
    "    dataY = []  \n",
    "    j=-1\n",
    "    for i, row in data.iterrows():\n",
    "        j=j+1\n",
    "        dataY.append(row['label'])\n",
    "        l = np.sum(reviews[j])\n",
    "        # elem = [row['user_id'],row['prod_id'],int(row['rating']),date.day,date.month,date.year] + [l] + reviews[index].tolist()\n",
    "        elem = [row['user_id'],row['prod_id'],int(row['rating'])] + [l]\n",
    "        #elem = [row['user_id'],row['prod_id'],int(row['rating'])] + [l] + reviews[j].tolist()\n",
    "        dataX.append(elem)\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = load_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250874, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25819\n",
      "225055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    25819\n",
       "0    25819\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "\n",
    "from sklearn.utils import resample\n",
    "df_majority = data[data.label==0]\n",
    "df_minority = data[data.label==1]\n",
    "print(len(df_minority))\n",
    "print(len(df_majority))\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=len(df_minority),     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "data = df_downsampled\n",
    "# Display new class counts\n",
    "df_downsampled.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51638, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love ive got word mango chutney mayo omg it heavenli fri topper ive indulg in frite expens total worth it im fan especial sauc horseradish mayo horseradish bomb definit prefer spot taken asian play cute frenchbelgian tune regularli hear disney song kind take away cramp wood fill rustic interior\n"
     ]
    }
   ],
   "source": [
    "# clean review\n",
    "review = review_cleaning(data['review'])\n",
    "print(review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51638"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary list =  4481\n"
     ]
    }
   ],
   "source": [
    "# create vocabulary List\n",
    "vocabularyList = create_voc(review);\n",
    "print(\"Size of Vocabulary list = \",len(vocabularyList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create review feature\n",
    "rf = createFeatureVectors(review, vocabularyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51638, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX, dataY = preprocessing(data, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX,dataY,test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75393912 -0.84381779  0.5        -0.62637363]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6662148205525432\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6533785363572597\n",
      "Recall: 0.7169980756895445\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4732 2965]\n",
      " [2206 5589]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.65      7697\n",
      "           1       0.65      0.72      0.68      7795\n",
      "\n",
      "    accuracy                           0.67     15492\n",
      "   macro avg       0.67      0.67      0.67     15492\n",
      "weighted avg       0.67      0.67      0.67     15492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "conf = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
